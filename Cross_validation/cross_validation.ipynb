{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 교차검증은 왜 필요한가?\n",
    "<hr>\n",
    "\n",
    "![교차검증필요한이유1](cross_validation_imgs/교차검증필요한이유1.png)\n",
    "\n",
    "- train set 과 validation set 으로 구분하지 않는다면, 우리는 test set 으로만 모델을 테스트 하고 검증할 것임.\n",
    "- **한 가지 약점이 존재하는데 - test set 에만 강건한 모델이 될 수 있고, testset에 overfit될 수 있다는 것** -> test set 결과가 70%야 그러면 그걸 바탕으로 다시 모델 파라미터 튜닝을 하게 될 것이고 점점더 test set에 오버피팅 됨\n",
    "\n",
    "- test set 과적합 되어 다른 실제 데이터를 가지고 예측을 수행하면 엉망인 결과가 나올 수 있다. ==> **교차검증의 등장!**\n",
    "\n",
    "<hr>\n",
    "\n",
    "![cross_validation1](cross_validation_imgs/cross_validation1.png)\n",
    "- 교차검증은 데이터의 모든 부분을 사용하여 모델을 검증하고 test set을 하나로 고정하지 않기 때문에 test set에 overfit 되는 것을 막을 수 있음.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 교차 검증의 장점과 단점\n",
    "\n",
    "## 장점 \n",
    "### 1. 모든 데이터 셋을 평가에 활용할 수 있다.\n",
    "- 평가에 사용되는 데이터 편중을 막을 수 있다. \n",
    "- (특정 평가 데이터 셋에 overfit 되는 것을 방지할 수 있다.)\n",
    "- 평가 결과에 따라 좀 더 일반화된 모델을 만들 수 있다. \n",
    "- 일반적으로 Train, Validation, Test -> 6:2:2 가 일반적\n",
    "\n",
    "### 2. 모든 데이터 셋을 훈련에 활용할 수 있다.\n",
    "- 정확도를 향상시킬 수 있다.\n",
    "- 데이터 부족으로 인한 underfitting을 방지할 수 있다. (적을때 이걸 또 테스트셋으로 나누게되면 부족할 수 있으니까)\n",
    "\n",
    "## 단점\n",
    "- Iteration 횟수가 많기 때문에 모델 훈련/평가 시간이 오래 걸린다.\n",
    "\n",
    "\n",
    "## ■ 데이터셋 구성방법\n",
    "\n",
    "### 1. 홀드아웃 방법(Holdout method)\n",
    "\n",
    "![holdout](cross_validation_imgs/holdout.png)\n",
    "\n",
    "- 주어진 dataset을 임의의 비율로 train set과 test set 으로 분할하여 사용하는 것.\n",
    "- 9:1 / 7:3 비율이 가장 자주 쓰임. 훈련 및 검증 과정에 대한 iteration을 한 번만 하기 때문에 계산 시간에 대한 부담이 적은 것이 장점\n",
    "- test set에 관한 검증 결과 확인 후 모델 파라미터 튜닝을 하는 작업을 반복하게 되면 모델이 test set 에 대해 overfit될 가능성이 높음.\n",
    "- 가장 좋은 방법은 훈련, 검증, 테스트 세 가지로 나누는 방법 \n",
    "    - 훈련데이터 : 모델 훈련\n",
    "    - 검증데이터 : 모델 훈련에 적절한 지점을 찾기 위한 셋 / 모델 선택\n",
    "    - 테스트데이터 : 모델 성능을 최종 평가하기 위해 사용하는 데이터 셋\n",
    "    \n",
    "![데이터셋구성](cross_validation_imgs/데이터셋구성.png)\n",
    "\n",
    "### 2. Random subsampling\n",
    "- Holdout 방식 반복 / K개의 부분 데이터셋 사용 : 각 데이터셋은 랜덤\n",
    "\n",
    "### 3~4. Cross Validation / Stratified sampling\n",
    "### 5. 부트스트랩 (bootstrap)\n",
    "- 중복 추출 허용 or 비허용\n",
    "\n",
    "## ■ 교차검증 방법\n",
    "\n",
    "### 1. k-겹 교차 검증 방법 (k-fold cross validation)\n",
    "- **가장 일반적인 교차검증 방법**\n",
    "- 데이터를 k개의 데이터 폴드로 분할하고, 각 iteration 마다 중복되지 않는 test set을 다르게 할당\n",
    "- 총 k개의 데이터 폴드셋트를 구성하여 모델 학습하는데 총 k번의 iteration이 필요함.\n",
    "- 각 데이터 폴드 세트에 대해서 나온 검증 결과들을 평균내어 최종적인 검증 결과를 도출하는 것이 일반적\n",
    "- 계산시간에 대한 부담감 조금있음.\n",
    "- 적은 데이터셋에 매우 적합.\n",
    "\n",
    "![kfold_cross_validation](cross_validation_imgs/kfold_cross_validation.png)\n",
    "\n",
    "### 2. 리브-p-아웃 교차검증 (Leave-p-out-cross-validation) = (LOOCV)\n",
    "- 폴드갯수가 훈련 샘플 갯수와 같고, 아주 작은 데이터셋에서 유의함.\n",
    "- 전체 데이터 중에서 p개의 샘플을 선택하여 그것을 모델 검증에 사용하는 방법\n",
    "- test set 을 구성할 수 있는 경우의 수 ( 훈련 및 검증에 대한 iteration 수) 는 nCp와 같음\n",
    "- 경우의 수가 매우 크기 때문에 계산 시간에 대한 부담이 매우 큰 방법\n",
    "![leave_p_out_crossvalidation](cross_validation_imgs/leave_p_out_crossvalidation.png)\n",
    "\n",
    "### 3. 계층적 k-겹 교차 검증(Stratifield k-fold cross validation)\n",
    "- **주로 분류 문제에서 사용 : label의 분포가 각 클래스별로 불균형을 이룰때 유용하게 사용됨 **\n",
    "- label의 분포가 불균형일 때 index순으로 데이터 폴드 셋트를 구성하는 것은 데이터를 검증하는데 오류를 야기할 수 있음. (앞쪽에 00000011111 뒤쪽에 2222211222 이런경우)\n",
    "- 각 폴드에서는 전체 데이터셋 라벨이 가지고 있는 분포에 근사하게 데이터를 뽑아 줌..\n",
    "\n",
    "![stratifield_kfold_crossvalidation](cross_validation_imgs/stratifield_kfold_crossvalidation.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 set 구분에 대한 적절한 비율이란?\n",
    "- 사실 6:2:2 를 꼭 지키라는 법은 없고, 전통적은 7:3비율을 따를 필요는 없음.\n",
    "- 데이터가 많다면 (100만개) Train에 최대한 다양한 경우와 많은 데이터를 사용하되, \n",
    "- test data에 대한 1만개 정도만 해도 통계적으로 여러 가지 분포를 충분히 포함할 수 있다면 그렇게 해도 됨.\n",
    "\n",
    "## 언제 어떤걸?\n",
    "- **일반적으로 회귀에는 기본 k-겹 교차검증을 사용하고, 분류에는 StartifieldKFold를 사용**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 코드 \n",
    "### Scikit-learn 패키지의 sklearn.model_selection\n",
    "- 단순 데이터 분리 : train_test_split \n",
    "\n",
    "### train_test_split(data, data2, test_size, train_size, random_state)\n",
    "- data : 독립 변수 데이터 (numpy 배열, pandas 데이터프레임)\n",
    "- data2 : 종속 변수 데이터 (data 인수에 종속변수도 같이있다면 생략 가능)\n",
    "- test_size : 검증용 데이터 갯수 (1보다 작은 실수인 비율로도 표현 가능)\n",
    "- train_size : 학습용 데이터의 갯수 (1보다 작은 실수인 비율로도 표현 가능)\n",
    "- test_size나 train_size 둘중 하나만 있어도 됨)\n",
    "- random_stae : 난수 시드\n",
    "\n",
    "### KFold(n_split, shuffle, random_state)\n",
    "- n_split : Fold 갯수 / default=5\n",
    "- shuffle : 데이터 섞을 건지에 대한 여부 / default=False\n",
    "- random_state : 랜덤 난수 / default = None\n",
    "\n",
    "### StratifiedKFold\n",
    "- n_split : Fold 갯수 / default=5\n",
    "- shuffle : 데이터 섞을 건지에 대한 여부 / default=False\n",
    "- random_state : 랜덤 난수 / default = None\n",
    "\n",
    "### 실사용 method -> kf.split() / skf.split()\n",
    "- X : (n_samples, n_features), y(n_samples) 형태\n",
    "\n",
    "### cross_val_score\n",
    "- 일반 교차검증\n",
    "- cross_val_score ( 모델명, 훈련데이터, 타깃데이터, cv) / cv는 폴드 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (0) 데이터 로드\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "dfX = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "dfy = pd.DataFrame(boston.target, columns=[\"MEDV\"])\n",
    "df = pd.concat([dfX, dfy], axis=1) # 독립변수들과, 종속변수 합침.\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354, 14) (152, 14)\n",
      "훈련 데이터  (354, 13) (354, 1)\n",
      "테스트 데이터 (152, 13) (152, 1)\n"
     ]
    }
   ],
   "source": [
    "# (1) train_test_split 단순 데이터 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 독립변수, 종속변수 분리\n",
    "df_train, df_test = train_test_split(df, test_size=0.3, random_state=0)\n",
    "print(df_train.shape, df_test.shape)\n",
    "\n",
    "# 독립변수들, 종속변수들 같이\n",
    "dfX_train, dfX_test, dfy_train, dfy_test = train_test_split(dfX, dfy, test_size=0.3, random_state=0)\n",
    "print('훈련 데이터 ', dfX_train.shape, dfy_train.shape)\n",
    "print('테스트 데이터', dfX_test.shape, dfy_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] TEST: [0 1 2 3]\n",
      "TRAIN: [ 0  1  2  3  8  9 10 11 12 13 14 15 16 17 18 19] TEST: [4 5 6 7]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7 12 13 14 15 16 17 18 19] TEST: [ 8  9 10 11]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 16 17 18 19] TEST: [12 13 14 15]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15] TEST: [16 17 18 19]\n"
     ]
    }
   ],
   "source": [
    "# (2 -1) KFold 분리 - nonshuffle 버전\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "X = np.arange(20)\n",
    "\n",
    "# K-Fold 객체 생성\n",
    "kf = KFold(n_splits=5, shuffle=False, random_state=None) # KFold non shuffle 버전\n",
    "\n",
    "# kf.Split 반복\n",
    "for train, test in kf.split(X):\n",
    "    print(\"TRAIN:\", train, \"TEST:\", test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 0  1  3  4  5  6  7 10 11 12 13 14 15 16 17 19 20 21 22 23 24 25 28 29] TEST: [ 2  8  9 18 26 27]\n",
      "TRAIN: [ 0  2  4  5  7  8  9 10 11 12 14 17 18 19 20 21 22 23 24 25 26 27 28 29] TEST: [ 1  3  6 13 15 16]\n",
      "TRAIN: [ 0  1  2  3  5  6  7  8  9 11 12 13 15 16 18 19 20 21 23 24 26 27 28 29] TEST: [ 4 10 14 17 22 25]\n",
      "TRAIN: [ 1  2  3  4  5  6  8  9 10 11 13 14 15 16 17 18 20 22 23 24 25 26 27 28] TEST: [ 0  7 12 19 21 29]\n",
      "TRAIN: [ 0  1  2  3  4  6  7  8  9 10 12 13 14 15 16 17 18 19 21 22 25 26 27 29] TEST: [ 5 11 20 23 24 28]\n"
     ]
    }
   ],
   "source": [
    "# (2 - 2) KFold 분리 - shuffle 버전\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "X2 = np.arange(30)\n",
    "\n",
    "# K-Fold 객체 생성\n",
    "kf2 = KFold(n_splits=5, shuffle=True, random_state=77) # KFold shuffle 버전\n",
    "\n",
    "# kf2.Split 반복\n",
    "for train2, test2 in kf2.split(X2):\n",
    "    print(\"TRAIN:\", train2, \"TEST:\", test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kfold\n",
      "kTRAIN: [ 4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] kTEST: [0 0 2 1]\n",
      "kTRAIN: [ 0  1  2  3  8  9 10 11 12 13 14 15 16 17 18 19] kTEST: [0 0 0 1]\n",
      "kTRAIN: [ 0  1  2  3  4  5  6  7 12 13 14 15 16 17 18 19] kTEST: [2 2 1 1]\n",
      "kTRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 16 17 18 19] kTEST: [1 2 2 0]\n",
      "kTRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15] kTEST: [0 0 0 0]\n",
      "\n",
      "StratifieldKFold\n",
      "TRAIN: [ 4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] TEST: [0 0 2 1]\n",
      "TRAIN: [ 0  1  2  3  6  9 10 11 12 13 14 15 16 17 18 19] TEST: [0 0 1 2]\n",
      "TRAIN: [ 0  1  2  3  4  5  7  8 11 12 13 14 16 17 18 19] TEST: [0 2 1 0]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 12 14 15 18 19] TEST: [1 2 0 0]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 15 16 17] TEST: [1 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "# (3) StratifieldKFold 분리\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "X = np.arange(20)\n",
    "y = np.array([0,0,2,1,0,0,0,1,2,2,1,1,1,2,2,0,0,0,0,0])  \n",
    "# 0 -> 10개  1 -> 5개  2 -> 5개\n",
    "\n",
    "# 5fold 로 분리하게 되면 -> 2개 1개 1개 씩 분리될 것 균형있게\n",
    "kf3 = KFold(n_splits=5)\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "print('Kfold')\n",
    "for ktrain3, ktest3 in kf3.split(X,y):\n",
    "    print(\"kTRAIN:\", X[ktrain3], \"kTEST:\", y[ktest3])\n",
    "\n",
    "print('\\nStratifieldKFold')\n",
    "for train3, test3 in skf.split(X, y):\n",
    "    print(\"TRAIN:\", X[train3], \"TEST:\", y[test3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation score : [0.96666667 1.         0.93333333 0.96666667 1.        ]\n",
      "교차검증 평균 :  0.9733333333333334 \n",
      "\n",
      "StratifiedKFold cross validation score : [1.   0.92 1.   0.96 1.   0.92]\n",
      "계층별 k-겹 교차검증 0.9666666666666667 \n",
      "\n",
      "cross validation score : [1.   1.   0.92 0.92 0.88 0.84]\n",
      "KFold 검증 평균 : 0.93\n"
     ]
    }
   ],
   "source": [
    "# (4) cross_val_score\n",
    "# \n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# iris 데이터 로드\n",
    "iris = load_iris()\n",
    "\n",
    "# 로지스틱 회귀 (= 분류 기법)\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# 방법 1 - cross_val_score 를 이용한 기본 5fold\n",
    "score = cross_val_score(logreg, iris.data, iris.target, cv=5)\n",
    "print('cross validation score :', score)\n",
    "print('교차검증 평균 : ', score.mean(),'\\n')\n",
    "\n",
    "# 방법 2 - StratifieldKfold (데이터가 편향되어있을 경우)\n",
    "skf2 = StratifiedKFold(n_splits=6, shuffle = True, random_state=0)\n",
    "score2 = cross_val_score(logreg, iris.data, iris.target, cv = skf2)\n",
    "print('StratifiedKFold cross validation score : {}'.format(score2))\n",
    "print('계층별 k-겹 교차검증', score2.mean(), '\\n')\n",
    "\n",
    "# 방법 3 - KFold \n",
    "kfold = KFold(n_splits=6, shuffle=False, random_state=None)\n",
    "score3 = cross_val_score(logreg, iris.data, iris.target, cv=kfold)\n",
    "print('cross validation score : {}'.format(score3))\n",
    "print('KFold 검증 평균 : {:.2f}'.format(score3.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![stratifield_kfold_crossvalidation2](cross_validation_imgs/stratifield_kfold_crossvalidation2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 출처\n",
    "- https://m.blog.naver.com/PostView.nhn?blogId=ckdgus1433&logNo=221599517834&proxyReferer=https:%2F%2Fwww.google.com%2F\n",
    "- https://brunch.co.kr/@coolmindory/31\n",
    "- https://sgmath.tistory.com/61"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
