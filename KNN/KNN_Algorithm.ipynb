{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모수모델 vs 비모수모델 (Parametric Model vs NonParametric Model)\n",
    "\n",
    "## 모수모델 (Parametric Model)\n",
    "- 모수모델은 퍼셉트론, 로지스틱 회귀, 선형 SVM, 선형회귀모델, 회귀모델 등\n",
    "- **모수적 모델은 알려진 확률분포를 기반으로 해당 모수를 추정하는 과정이 포함되어 있는 모델.**\n",
    "- 반응변수를 이용해 예측변수를 설명하려고 할 때 실제로는 두 변수 사이의 랜덤성으로 인해 예측변수만을 가지고 반영변수를 100% 에측하기가 어렵다. 따라서 어쩔수 없이 오차(error)로 표현을 해야 하는데, 오차값들이 평균이 0이고 분산이 특정 상수값을 갖는 정규분포를 따른 다는 가정하에 수립될 수 있다. \n",
    "- 따라서 이렇듯 모델 구축시 알려진 확률분포(정규분포)를 가정하기 때문에 모수적 방법론에 속한다)\n",
    "- 훈련 데이터셋에서 모델 파라미터를 추정하며, 훈련이 끝나면 원본 훈련 데이터셋이 필요 없어짐\n",
    "\n",
    "## 비모수모델 (NonParametric Model)\n",
    "- 비모수모델은 결정 트리, 랜덤 포레트스, 커널 SVM, KNN 등\n",
    "- 예시로 KNN은 가장 가까운 거리에 있는 K개의 관측치를 결정한 후 이들의 특성을 이용해 관심 관측치를 예측하는 과정이기에, 여기서 확률분포와 같은 개념은 전혀 사용되지 않는다.\n",
    "- **따라서 모델을 구축함에 있어, 확률분포의 개념이 전혀 사용되지 않는다면 비모수 모델이다.**\n",
    "\n",
    "\n",
    "#### 쉬운 결론으로 확률분포의 개념이 사용되면 모수모델 / 사용 안되면 비모수모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN (K-Nearest Neighbor 알고리즘)\n",
    "- **최근접 이웃법은 새로운 데이터를 입력받았을 때 가장 가까이 있는 것이 무엇이냐를 중심으로 새로운 데이터의 종류를 정해주는 알고리즘**\n",
    "- KNN은 게으른 모델(Lazy model)이다. 조금 점잖게는 Instance-based Learning이라고 불리기도 함.\n",
    "- 이는 데이터로부터 모델을 생성해 과업을 수행하는 Model-based learning과 대비되는 개념으로, 별도 모델 생성과정 없이 각각의 관측치(instance)만을 이용하여 분류/회귀 등 과업을 수행한다는 취지\n",
    "\n",
    "![KNN1](img/KNN1.png)\n",
    "\n",
    "- 위와 같은 경우는 매우 직관적인 경우.\n",
    "\n",
    "![KNN2](img/KNN2.png)\n",
    "- 위와 같은 경우는 k=1, k=4 일때 어느경우가 좋은 경우인지를 모름. -> 적정한 k값을 찾아야 한다.\n",
    "- 가장 보편적으로는 총 데이터의 제곱근값 을 사용하기는 함.\n",
    "- K는 일반적으로 홀수 (만약 분류되는 정답의 확률이 같을 경우 먼저 발견한 것을 우선함)\n",
    "\n",
    "## KNN의 하이퍼 파라미터\n",
    "- **KNN의 하이퍼파라메터(Hyper parameter)는 탐색할 이웃 수(k), 거리 측정 방법 두 가지이다.**\n",
    "- k가 작을 경우 데이터의 지역적 특성을 지나치게 반영하게 됩니다(overfitting)\n",
    "- 반대로 매우 클 경우 모델이 과하게 정규화되는 경향이 있습니다(underfitting)\n",
    "\n",
    "## KNN의 거리지표\n",
    "\n",
    "#### (1) Euclidian (유클리디언 거리)\n",
    "- **가장 짧은 일반적인 직선 거리**\n",
    "![Euclidian](img/Euclidian.png)\n",
    "\n",
    "#### (2) Manhattan (맨해튼 거리)\n",
    "- 아래 그림에서의 route1,2,3 은 맨해튼 거리로 모두 같은 거리\n",
    "- 좌표계에서 실제 움직인만큼만 계산하는 방식?\n",
    "- **가로블록 + 세로블록 절대합**\n",
    "![Manhattan](img/Manhattan.png)\n",
    "![Manhattan2](img/Manhattan2.png)\n",
    "\n",
    "#### (3) Mahalanobis (마할라노비스 거리)\n",
    "- 변수 내 분산, 변수 간 공분산을 모두 반영하여 거리를 계산하는 방식. 변수 간 상관관계를 고려한 거리 지표\n",
    "![Mahalanobis](img/Mahalanobis.png)\n",
    "\n",
    "#### (4) Correlation Distance (상관관계 거리)\n",
    "- 데이터의 pearson correlation을 거리 척도로 직접 사용.\n",
    "- 개별 관측치 하나하나가 아니라 데이터 전체의 경향성을 비교하기 위한 척도로. 두 개 데이터 패턴의 유사도를 반영 가능. \n",
    "- 상관계수는 -1에서 1사이의 범위를 가지므로, Correlation Distance의 범위는 0에서 2 사이\n",
    "- 0이면 두 데이터의 패턴이 매우 유사한 것이고, 2이면 그렇지 않다고 해석.\n",
    "![correlation_distance](img/correlation_distance.png)\n",
    "\n",
    "\n",
    "## Best K 찾기\n",
    "- k를 1부터 10까지 증가시키며 오분류율을 점검하기. \n",
    "- 만약 k가 증가하는데 오분류율이 계속 낮아진다면 k를 좀더 키워볼 필요가 있음.\n",
    "\n",
    "## combining rule\n",
    "- KNN은 주변 이웃의분포에 따라 예측 결과가 충분히 달라질 수 있다.\n",
    "- 가장 단순한 결정 방식은 다수결(Majority voting)이고, \n",
    "- 가중합(weighted voting) 방식으로 거리(d)가 가까운(=유사도가 높은) 이웃의 정보에 좀 더 가중치를 주는 방식도 있음.\n",
    "\n",
    "## 데이터가 불균형 = cut-off 기준\n",
    "- 범주 간 비율이 불균형한 데이터일 때 컷오프 기준 설정시 학습데이터 범주의 사전확률(prior probability)를 고려해야 한다.\n",
    "\n",
    "## KNN 수행시 주의점\n",
    "- **KNN 수행 전 반드시 변수를 정규화(Normalization) 해주어야 함.**\n",
    "- 왜냐면 같은 좌표평면상?에 가니까 거리로 측정하니까 단위가 다르면 안됨.\n",
    "- 따라서 변수별로 평균과 분산을 일치시키는 정규화 작업을 반드시 KNN 적용 전 수행해 주어야 한다.\n",
    "\n",
    "## KNN의 장단점\n",
    "### 장점\n",
    "- 학습데이터 내에 끼어있는 노이즈의 영향을 크게 받지 않는다.\n",
    "- 학습데이터의 수가 많아지면 꽤 효과적인 알고리즘이고, 마할라노비스 거리와 같은 데이터의 분산을 고려할 경우 매우 강건(Robust)한 방법론으로 알려져 있다.\n",
    "\n",
    "### 단점\n",
    "- 새로운 관측치가 들어왔을 때 각각의 학습 데이터 사이의 거리를 전부 측정해야해서 계산 시간이 오래걸림\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 라이브러리 \n",
    "- sklearn.neighbors 라이브러리의 KNeighborsClassifier\n",
    "\n",
    "- KNeighborsClassifier(\n",
    "    n_neighbors=5, \n",
    "    weights='uniform', # 가중치\n",
    "    algorithm='auto',\n",
    "    leaf_size=30,\n",
    "    p=2,\n",
    "    metric='minkowski',\n",
    "    metric_params=None,\n",
    "    n_jobs=None,)   \n",
    "    \n",
    "\n",
    "- **weights : 가중치**\n",
    "    - uniform : 균일한 가중치로 각 이웃의 모든 포인트는 동일하게 가중치가 부여\n",
    "    - distance : 거리의 역수로 가중치를 나타냄. 인접이웃은 멀리 떨어진 이웃보다 더 큰 영향을 미침   \n",
    "   \n",
    "- **algorithm : 알고리즘 선택**\n",
    "    - ball_tree : \n",
    "    - kd_tree : \n",
    "    - brute : 무차별 검색\n",
    "    - auto : fit메소드에 전달된 값을 기반으로 가장 적합한 알고리즘 결정하려고 시도   \n",
    "    \n",
    "- leaf_size : 잎 크기는 BallTree 또는 KDTree로 전달.   \n",
    "\n",
    "- p : Power parameter 거리지표 (Minkowski 지표)\n",
    "    - p=1 (맨해튼) / p=2(유클리디언) / 임의의 p는 Minkowski distance\n",
    "    - Minkowski Distance(민코우스키 거리)에서 r=1이면 맨해튼, r=2이면 유클리디언 거리   \n",
    "    \n",
    "### (2) 내부 메소드\n",
    "- get_params() : Get parameters for this estimator\n",
    "- kneigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 4) (38, 4) (112,) (38,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Iris Data Load \n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Train a model.\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.72220002 -1.7560208  -1.51628983 -1.28193925]\n",
      " [-1.60224579  0.32396623 -1.45834903 -1.41574838]\n",
      " [ 0.19706766 -0.13825311  0.56957868  0.72519769]]\n",
      "[[-0.52265772  1.01729524 -1.51628983 -1.41574838]\n",
      " [-1.12242887  1.24840491 -1.45834903 -1.41574838]\n",
      " [ 0.19706766 -0.13825311  0.3957563   0.18996118]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "print(X_train[:3])\n",
    "print(X_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# \n",
    "classifier.fit(X_train, y_train)\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 0, 0, 2, 0, 1, 0, 0, 0, 2, 1, 2, 0, 1, 2, 2, 0, 1,\n",
       "       2, 1, 1, 1, 2, 2, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17  0  0]\n",
      " [ 0  9  2]\n",
      " [ 0  1  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        17\n",
      "           1       0.90      0.82      0.86        11\n",
      "           2       0.82      0.90      0.86        10\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.91      0.91      0.90        38\n",
      "weighted avg       0.92      0.92      0.92        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 0. , 0. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [0. , 1. , 0. ],\n",
       "       [0. , 1. , 0. ],\n",
       "       [0. , 0.6, 0.4],\n",
       "       [1. , 0. , 0. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [0. , 0.2, 0.8],\n",
       "       [1. , 0. , 0. ],\n",
       "       [0. , 1. , 0. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [0. , 0.2, 0.8],\n",
       "       [0. , 1. , 0. ],\n",
       "       [0. , 0.2, 0.8],\n",
       "       [1. , 0. , 0. ],\n",
       "       [0. , 1. , 0. ],\n",
       "       [0. , 0. , 1. ],\n",
       "       [0. , 0.4, 0.6],\n",
       "       [1. , 0. , 0. ],\n",
       "       [0. , 0.6, 0.4],\n",
       "       [0. , 0. , 1. ],\n",
       "       [0. , 1. , 0. ],\n",
       "       [0. , 1. , 0. ],\n",
       "       [0. , 1. , 0. ],\n",
       "       [0. , 0.2, 0.8],\n",
       "       [0. , 0. , 1. ],\n",
       "       [0. , 0. , 1. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [0. , 0. , 1. ],\n",
       "       [0. , 0. , 1. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [1. , 0. , 0. ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 분류 결과 확률로\n",
    "classifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                    metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                    weights='uniform')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K-Neighbors 회귀\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# knn 회귀\n",
    "neigh = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# 학습\n",
    "neigh.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0. , 1. , 1. , 1.4, 0. , 0. , 1.8, 0. , 1. , 0. , 0. , 0. ,\n",
       "       1.8, 1. , 1.8, 0. , 1. , 2. , 1.6, 0. , 1.4, 2. , 1. , 1. , 1. ,\n",
       "       1.8, 2. , 2. , 0. , 0. , 2. , 2. , 0. , 0. , 0. , 0. , 0. ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = neigh.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 출처\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor // scikit learn kneighbors\n",
    "- https://gomguard.tistory.com/51\n",
    "\n",
    "- https://ratsgo.github.io/machine%20learning/2017/04/17/KNN/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
